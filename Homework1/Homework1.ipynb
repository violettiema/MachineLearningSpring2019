{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===============================================================================================================\n",
    "\n",
    "# Machine Learning Homework 1\n",
    "\n",
    "# Violet Tiema\n",
    "\n",
    "# Jan 24 2018\n",
    "\n",
    "===============================================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 500 documents in the docs directory\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(\"/Users/violet/Desktop/Machine Learning/homework-1-data-set/docs\"):\n",
    "    f.extend(filenames)\n",
    "    \n",
    "    #break\n",
    "    \n",
    "f.pop(0)                  #a list of the filenames\n",
    "\n",
    "print('There are',len(f),'documents in the docs directory')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have d = $(d_1, \\dots, d_n)^T \\in \\mathbb{R}^n $ represents the vector representation for a document where $d_i$ is the term frequency of i'th term in the vocabulary. Similarly, each query will be denoted as\n",
    "q = $(q_1, \\dots, q_n)^T \\in \\mathbb{R}^n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "import gensim\n",
    "\n",
    "\n",
    "folder_path = \"/Users/violet/Desktop/Machine Learning/homework-1-data-set/docs\"\n",
    "\n",
    "document_collection = [] \n",
    "\n",
    "#a hash table that maps words to integer ids and keeps frequency of the words\n",
    "word_to_id = {} \n",
    "\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        #print(filename)             #a list of the filenames\n",
    "        \n",
    "        text = f.readlines()\n",
    "        text = [x.strip() for x in text] \n",
    "        document_collection.append(text)\n",
    "\n",
    "\n",
    "for document in document_collection:\n",
    "    for word in document:\n",
    "        if word in word_to_id :\n",
    "            word_to_id[word] += 1\n",
    "        else:\n",
    "            word_to_id[word] = 1\n",
    "        \n",
    "        \n",
    "#print the vocabulary:\n",
    "#for (word, word_integer_id) in word_to_id.items():\n",
    "    #print (word, word_integer_id)\n",
    "    \n",
    "\n",
    "# creating vectors for all the documents in the docs folder.\n",
    "\n",
    "n = len(word_to_id)\n",
    "\n",
    "# list that has all the vocabulary\n",
    "dictionary = gensim.corpora.Dictionary(document_collection)\n",
    "corpus = [dictionary.doc2bow(document) for document in document_collection]\n",
    "\n",
    "  \n",
    "#create a vector of dimension the vocabulary size\n",
    "doc_vectors = numpy.zeros(shape = (500, n), dtype = float)       \n",
    "   \n",
    "\n",
    "for i in range(len(document_collection)):\n",
    "    for stuff in dictionary:\n",
    "        for word in document_collection[i]:\n",
    "            if dictionary[stuff] == word:\n",
    "                doc_vectors[i][stuff] = word_to_id[word]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "\n",
    "folder_path = \"/Users/violet/Desktop/Machine Learning/homework-1-data-set/queries\"\n",
    "\n",
    "query_collection = [] \n",
    "\n",
    "#a hash table that maps words to integer ids\n",
    "query_to_id = {} \n",
    "\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.readlines()\n",
    "        text = [x.strip() for x in text] \n",
    "        query_collection.append(text)\n",
    "\n",
    "\n",
    "for document in query_collection:\n",
    "    for word in document:\n",
    "        if word in query_to_id :\n",
    "            query_to_id[word] += 1\n",
    "        else:\n",
    "            query_to_id[word] = 1\n",
    "        \n",
    "        \n",
    "# print the vocabulary:\n",
    "#for (query, query_integer_id) in query_to_id.items():\n",
    "    #print (query, query_integer_id)\n",
    "    \n",
    "    \n",
    "# list that has all the vocabulary\n",
    "dictionary2 = gensim.corpora.Dictionary(query_collection)\n",
    "corpus2 = [dictionary2.doc2bow(query) for query in query_collection]\n",
    "    \n",
    "\n",
    "#create a vector of dimension the vocabulary size\n",
    "query_vectors = numpy.zeros(shape = (5, n), dtype = float)       \n",
    "   \n",
    "\n",
    "for i in range(len(query_collection)):\n",
    "    for stuff in dictionary2:\n",
    "        for word in query_collection[i]:\n",
    "            if dictionary2[stuff] == word:\n",
    "                query_vectors[i][stuff] = query_to_id[word]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SIMILARITY MEASURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "dot_sim = numpy.zeros(shape = (5, 500), dtype = float)       \n",
    "cosine_sim = numpy.zeros(shape = (5, 500), dtype = float) \n",
    "\n",
    "\n",
    "for j in range(0, len(query_vectors)):\n",
    "    \n",
    "    for i in range(0, len(doc_vectors)):  \n",
    "        sums = 0.0 \n",
    "        norm1 = 0.0    # the sum of squares of the components of query_vectors\n",
    "        norm2 = 0.0    # the sum of squares of the components of document_vectors\n",
    "\n",
    "        for k in range(0, len(doc_vectors[i])):\n",
    "            sums += query_vectors[j][k] * doc_vectors[i][k]\n",
    "            norm1 += query_vectors[j][k] * query_vectors[j][k]\n",
    "            norm2 += doc_vectors[i][k] * doc_vectors[i][k]\n",
    "        \n",
    "        \n",
    "        # must guard against norm1 and norm2 being zero\n",
    "        # this means that at least one of the documents has no words\n",
    "        normalization = m.sqrt(norm1) * m.sqrt(norm2)\n",
    "        cosine_similarity = sums/normalization\n",
    "        \n",
    "        \n",
    "        \n",
    "        dot_sim[j][i] = sums\n",
    "        cosine_sim[j][i] = cosine_similarity\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"homework-1-data-set/docs\"\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        \n",
    "        filenames.append(filename[25:])             #a list of the filenames\n",
    "        \n",
    "        text = f.readlines()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dot = []\n",
    "\n",
    "for i in dot_sim:\n",
    "    m = []\n",
    "    for j in range(len(i)):\n",
    "        v = (i[j],filenames[j] )\n",
    "        m.append(v)\n",
    "    new_dot.append(m)\n",
    "    \n",
    "new_sim = []\n",
    "    \n",
    "for i in cosine_sim:\n",
    "    m = []\n",
    "    for j in range(len(i)):\n",
    "        v = (i[j],filenames[j] )\n",
    "        m.append(v)\n",
    "    new_sim.append(m)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dot = []\n",
    "\n",
    "for i in range(len(new_dot)):\n",
    "    news = [tuple(v) for v in dict(new_dot[i]).items()]  \n",
    "    news_dot.append(news)\n",
    "\n",
    "    \n",
    "news_sim = []\n",
    "\n",
    "for i in range(len(new_sim)):\n",
    "    new = [tuple(v) for v in dict(new_sim[i]).items()]  \n",
    "    news_sim.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HA = []\n",
    "HA2 = []\n",
    "\n",
    "for i in range(len(news_dot)):\n",
    "    ha = sorted(news_dot[i], reverse = True)[:11]\n",
    "    HA.append(ha)\n",
    "\n",
    "for i in range(len(news_sim)):\n",
    "    ha = sorted(news_sim[i], reverse = True)[:11]\n",
    "    HA2.append(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product similarity, the 10 most similar documents are:\n",
      "For Query : 1\n",
      "Document: 10000 with dot product similarity score: 71.0\n",
      "Document: 10011 with dot product similarity score: 64.0\n",
      "Document: 59913 with dot product similarity score: 58.0\n",
      "Document: 59905 with dot product similarity score: 39.0\n",
      "Document: 10078 with dot product similarity score: 25.0\n",
      "Document: 60152 with dot product similarity score: 19.0\n",
      "Document: 60206 with dot product similarity score: 7.0\n",
      "Document: 59848 with dot product similarity score: 6.0\n",
      "Document: 60232 with dot product similarity score: 0.0\n",
      "For Query : 2\n",
      "Document: 10000 with dot product similarity score: 81.0\n",
      "Document: 100521 with dot product similarity score: 62.0\n",
      "Document: 10034 with dot product similarity score: 59.0\n",
      "Document: 101565 with dot product similarity score: 50.0\n",
      "Document: 51153 with dot product similarity score: 47.0\n",
      "Document: 60226 with dot product similarity score: 42.0\n",
      "Document: 102677 with dot product similarity score: 31.0\n",
      "Document: 10001 with dot product similarity score: 25.0\n",
      "Document: 59871 with dot product similarity score: 20.0\n",
      "Document: 60206 with dot product similarity score: 17.0\n",
      "Document: 60212 with dot product similarity score: 14.0\n",
      "For Query : 3\n",
      "Document: 10001 with dot product similarity score: 128.0\n",
      "Document: 59874 with dot product similarity score: 121.0\n",
      "Document: 60220 with dot product similarity score: 88.0\n",
      "Document: 10082 with dot product similarity score: 85.0\n",
      "Document: 51119 with dot product similarity score: 69.0\n",
      "Document: 60215 with dot product similarity score: 52.0\n",
      "Document: 49960 with dot product similarity score: 40.0\n",
      "Document: 60169 with dot product similarity score: 36.0\n",
      "Document: 102651 with dot product similarity score: 33.0\n",
      "Document: 60214 with dot product similarity score: 7.0\n",
      "Document: 60232 with dot product similarity score: 0.0\n",
      "For Query : 4\n",
      "Document: 59874 with dot product similarity score: 60.0\n",
      "Document: 10001 with dot product similarity score: 49.0\n",
      "Document: 10011 with dot product similarity score: 47.0\n",
      "Document: 59904 with dot product similarity score: 36.0\n",
      "Document: 10062 with dot product similarity score: 24.0\n",
      "Document: 59873 with dot product similarity score: 13.0\n",
      "Document: 60224 with dot product similarity score: 11.0\n",
      "Document: 102637 with dot product similarity score: 7.0\n",
      "Document: 101620 with dot product similarity score: 6.0\n",
      "Document: 60232 with dot product similarity score: 0.0\n",
      "For Query : 5\n",
      "Document: 10002 with dot product similarity score: 87.0\n",
      "Document: 59873 with dot product similarity score: 53.0\n",
      "Document: 10054 with dot product similarity score: 48.0\n",
      "Document: 60103 with dot product similarity score: 39.0\n",
      "Document: 60162 with dot product similarity score: 25.0\n",
      "Document: 59913 with dot product similarity score: 14.0\n",
      "Document: 10046 with dot product similarity score: 9.0\n",
      "Document: 60232 with dot product similarity score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Dot product similarity, the 10 most similar documents are:\")\n",
    "for i in range(len(query_collection)):\n",
    "    print(\"For Query :\", i+1)\n",
    "    \n",
    "    for j in HA[i]:\n",
    "        print(\"Document:\", j[1], \"with dot product similarity score:\", j[0] )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity, the 10 most similar documents are:\n",
      "For Query : 1\n",
      "Document: 10000 with cosine similarity score: 0.37420285645325824\n",
      "Document: 10010 with cosine similarity score: 0.05852769014770931\n",
      "Document: 10011 with cosine similarity score: 0.04763218144195262\n",
      "Document: 10067 with cosine similarity score: 0.04353037743890036\n",
      "Document: 10047 with cosine similarity score: 0.041828714392830306\n",
      "Document: 59913 with cosine similarity score: 0.04131217604437431\n",
      "Document: 10078 with cosine similarity score: 0.031227855591500805\n",
      "Document: 59872 with cosine similarity score: 0.027687078846111306\n",
      "Document: 101629 with cosine similarity score: 0.02516426064386473\n",
      "Document: 59873 with cosine similarity score: 0.023431780048725072\n",
      "Document: 59905 with cosine similarity score: 0.02219455774218973\n",
      "For Query : 2\n",
      "Document: 10000 with cosine similarity score: 0.6037383539249432\n",
      "Document: 51214 with cosine similarity score: 0.14931404541650153\n",
      "Document: 101592 with cosine similarity score: 0.1416963404573178\n",
      "Document: 51163 with cosine similarity score: 0.14125809089096805\n",
      "Document: 10053 with cosine similarity score: 0.1346444345638479\n",
      "Document: 101579 with cosine similarity score: 0.13255792804457775\n",
      "Document: 60159 with cosine similarity score: 0.12557863711500486\n",
      "Document: 10001 with cosine similarity score: 0.12311835609717749\n",
      "Document: 101565 with cosine similarity score: 0.12247179278935508\n",
      "Document: 102618 with cosine similarity score: 0.1210863597006431\n",
      "Document: 102640 with cosine similarity score: 0.12032358990442013\n",
      "For Query : 3\n",
      "Document: 10001 with cosine similarity score: 0.7720375050454092\n",
      "Document: 60169 with cosine similarity score: 0.4677297303012687\n",
      "Document: 101623 with cosine similarity score: 0.34354038354048083\n",
      "Document: 10082 with cosine similarity score: 0.2737097858471986\n",
      "Document: 51123 with cosine similarity score: 0.2705692344569338\n",
      "Document: 10049 with cosine similarity score: 0.24787773988805925\n",
      "Document: 60220 with cosine similarity score: 0.22575979971196505\n",
      "Document: 101612 with cosine similarity score: 0.2220114851219782\n",
      "Document: 10062 with cosine similarity score: 0.18798673906001537\n",
      "Document: 60192 with cosine similarity score: 0.17834174423268262\n",
      "Document: 102629 with cosine similarity score: 0.1732755844284044\n",
      "For Query : 4\n",
      "Document: 10001 with cosine similarity score: 0.264344027439321\n",
      "Document: 101638 with cosine similarity score: 0.22156468376279892\n",
      "Document: 101646 with cosine similarity score: 0.16475498044528689\n",
      "Document: 102585 with cosine similarity score: 0.13716898705776373\n",
      "Document: 101578 with cosine similarity score: 0.13010301390485648\n",
      "Document: 10002 with cosine similarity score: 0.11332611951597255\n",
      "Document: 101569 with cosine similarity score: 0.11039880769931523\n",
      "Document: 102628 with cosine similarity score: 0.0937360159061932\n",
      "Document: 10035 with cosine similarity score: 0.09083555601445441\n",
      "Document: 102623 with cosine similarity score: 0.09016922609741237\n",
      "Document: 102651 with cosine similarity score: 0.08420044855049784\n",
      "For Query : 5\n",
      "Document: 10002 with cosine similarity score: 0.4592963936909641\n",
      "Document: 101599 with cosine similarity score: 0.2936067815803641\n",
      "Document: 101612 with cosine similarity score: 0.16650861384148366\n",
      "Document: 10090 with cosine similarity score: 0.1642021572224399\n",
      "Document: 10023 with cosine similarity score: 0.14294580242184762\n",
      "Document: 10055 with cosine similarity score: 0.13917714030434608\n",
      "Document: 10048 with cosine similarity score: 0.1332556745916338\n",
      "Document: 10050 with cosine similarity score: 0.1275900431508089\n",
      "Document: 10037 with cosine similarity score: 0.11606937237201884\n",
      "Document: 10054 with cosine similarity score: 0.11215320623121086\n",
      "Document: 102607 with cosine similarity score: 0.1042644604606976\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity, the 10 most similar documents are:\")\n",
    "for i in range(len(query_collection)):\n",
    "    print(\"For Query :\", i+1)\n",
    "    for j in HA2[i]:\n",
    "\n",
    "        print(\"Document:\", j[1], \"with cosine similarity score:\", j[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
