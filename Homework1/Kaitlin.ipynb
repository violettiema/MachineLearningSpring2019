{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_search(docfilespath,queryfilespath,num):\n",
    "\n",
    "    import os, glob\n",
    "    import numpy as np\n",
    "    \n",
    "    folder_path = docfilespath\n",
    "    doc_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    vocab = []\n",
    "    k = 0\n",
    "    for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "        with open(filename, 'r') as f:\n",
    "            k += 1\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line not in vocab:\n",
    "                    vocab.append(line)\n",
    "                    \n",
    "    mat = [] \n",
    "    for x in range(len(vocab)):\n",
    "        name = [0]*k\n",
    "        mat.append(name)\n",
    "    \n",
    "    query_files = [f for f in os.listdir(folder_path_query) if os.path.isfile(os.path.join(folder_path_query, f))]\n",
    "    i = 0\n",
    "    for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                ind = vocab.index(line)\n",
    "                mat[ind][i] += 1\n",
    "        i += 1\n",
    "         \n",
    "    folder_path_query = queryfilespath\n",
    "    \n",
    "    a = 0\n",
    "    for filename in glob.glob(os.path.join(folder_path_query, '*')):\n",
    "        with open(filename, 'r') as f:\n",
    "            a += 1\n",
    "            \n",
    "    mat_q = [] \n",
    "    for y in range(len(vocab)):\n",
    "        name = [0]*a\n",
    "        mat_q.append(name)\n",
    "    \n",
    "    j = 0\n",
    "    for filename in glob.glob(os.path.join(folder_path_query, '*')):\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                ind = vocab.index(line)\n",
    "                mat_q[ind][j] += 1\n",
    "        j += 1\n",
    "        \n",
    "    docs = np.array(mat)\n",
    "    queries = np.array(mat_q)\n",
    "    \n",
    "    sim_dot = np.dot(np.transpose(docs),queries)\n",
    "    docs_norm = np.ndarray(shape = docs.shape, dtype = float)\n",
    "    queries_norm = np.ndarray(shape = queries.shape, dtype = float)\n",
    "    \n",
    "    for col in range(docs.shape[1]):\n",
    "        docs_norm[:,col] = np.divide(docs[:,col],np.linalg.norm(docs[:,col]))\n",
    "        \n",
    "    for col in range(queries.shape[1]):\n",
    "        q_norm = np.linalg.norm(queries[:,col])\n",
    "        queries_norm[:,col] = np.divide(queries[:,col],q_norm)\n",
    "    \n",
    "    \n",
    "    sim_cos = np.dot(np.transpose(docs_norm),queries_norm)\n",
    "    \n",
    "    sim_dot_sort = np.ndarray(shape = sim_dot.shape, dtype = int)\n",
    "    sim_cos_sort = np.ndarray(shape = sim_cos.shape, dtype = int)\n",
    "    \n",
    "    for col in range(sim_dot.shape[1]):\n",
    "        sim_dot_sort[:,col] = np.argsort(sim_dot[:,col])\n",
    "        sim_cos_sort[:,col] = np.argsort(sim_cos[:,col])\n",
    "        \n",
    "    doc_list_dot = np.ndarray(shape = sim_dot_sort.shape, dtype = int)\n",
    "    doc_list_cos = np.ndarray(shape = sim_cos_sort.shape, dtype = int)\n",
    "    sim_list_dot = np.ndarray(shape = sim_dot_sort.shape, dtype = float)\n",
    "    sim_list_cos = np.ndarray(shape = sim_cos_sort.shape, dtype = float)\n",
    "        \n",
    "    for col in range(sim_dot_sort.shape[1]):\n",
    "        for row in range(sim_dot_sort.shape[0]):\n",
    "            doc_list_dot[row,col] = doc_files[sim_dot_sort[row,col]]\n",
    "            doc_list_cos[row,col] = doc_files[sim_cos_sort[row,col]]\n",
    "            sim_list_dot[row,col] = sim_dot[sim_dot_sort[row,col],col]\n",
    "            sim_list_cos[row,col] = sim_cos[sim_cos_sort[row,col],col]\n",
    "    \n",
    "    for x in range(len(query_files)):\n",
    "        print(\"For Query\", x+1, \"the top\", num, \"documents using dot product similarity are:\")\n",
    "        for y in range(num):\n",
    "            print(\"Document\", y+1, \":\", doc_list_dot[doc_list_dot.shape[0] - (y+1),x], \" with similarity score:\", sim_list_dot[sim_list_dot.shape[0] - (y+1),x])\n",
    "        print(\"For Query\", x+1, \"the top\", num, \"documents using cosine similarity are:\")\n",
    "        for y in range(num):\n",
    "            print(\"Document\", y+1, \":\", doc_list_cos[doc_list_cos.shape[0] - (y+1),x], \" with similarity score:\", sim_list_cos[sim_list_cos.shape[0] - (y+1),x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "belief\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "christian\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "religious\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "religious\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "religious /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/1\n",
      "astronomy\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "moon\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "venus\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "astronaut\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "telescope\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "spacecraft /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/2\n",
      "cpu\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/3\n",
      "application\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/3\n",
      "hardware\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/3\n",
      "software\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/3\n",
      "education\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/4\n",
      "student\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/4\n",
      "school\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/4\n",
      "scientific\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/4\n",
      "sciences /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/4\n",
      "games\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/5\n",
      "baseball\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/5\n",
      "winning\n",
      " /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/5\n",
      "sport /Users/violet/Desktop/Machine Learning/homework-1-data-set/queries/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'kermit' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9db0d56540c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mmat_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'kermit' is not in list"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "docfilespath = \"/Users/violet/Desktop/Machine Learning/homework-1-data-set/queries\"\n",
    "queryfilespath = \"/Users/violet/Desktop/Machine Learning/homework-1-data-set/docs\"\n",
    "\n",
    "folder_path = docfilespath\n",
    "doc_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "vocab = []\n",
    "k = 0\n",
    "for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "    with open(filename, 'r') as f:\n",
    "        k += 1\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line not in vocab:\n",
    "                vocab.append(line)\n",
    "\n",
    "mat = [] \n",
    "for x in range(len(vocab)):\n",
    "    name = [0]*k\n",
    "    mat.append(name)\n",
    "\n",
    "query_files = [f for f in os.listdir(folder_path_query) if os.path.isfile(os.path.join(folder_path_query, f))]\n",
    "i = 0\n",
    "for filename in glob.glob(os.path.join(folder_path, '*')):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            print(line, filename)\n",
    "            line = line.strip()\n",
    "            ind = vocab.index(line)\n",
    "            mat[ind][i] += 1\n",
    "    i += 1\n",
    "\n",
    "folder_path_query = queryfilespath\n",
    "\n",
    "a = 0\n",
    "for filename in glob.glob(os.path.join(folder_path_query, '*')):\n",
    "    with open(filename, 'r') as f:\n",
    "        a += 1\n",
    "\n",
    "mat_q = [] \n",
    "for y in range(len(vocab)):\n",
    "    name = [0]*a\n",
    "    mat_q.append(name)\n",
    "\n",
    "j = 0\n",
    "for filename in glob.glob(os.path.join(folder_path_query, '*')):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            ind = vocab.index(line)\n",
    "            mat_q[ind][j] += 1\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
